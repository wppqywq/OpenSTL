\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{xcolor}

\newcommand{\todo}[1]{\textbf{\color{red}TODO: #1}}

\title{Moving MNIST: A Compact, Reproducible Benchmark Plan\\
for Zero-shot Video Prediction and Motion Stress Tests}
\author{ }
\date{\today}

\begin{document}
\maketitle

\begin{abstract}
\todo{1-2 paragraphs: What problem we answer; why Moving MNIST alone is insufficient; what we add (pixel audit, patch detaching, motion controller), zero-shot protocol, long-horizon rollout, and sensitivity study.}
\end{abstract}

\section{Introduction}
Spatio-temporal predictive learning (STL) aims to forecast future frames from past observations without labels, learning spatial and temporal regularities in the process \cite{openstl2023}. This report specifies a reproducible, zero-shot evaluation protocol on Moving MNIST \cite{srivastava2015}, augmented with stress tests on speed and position-dependent motion fields. We target top recurrent and non-recurrent baselines (e.g., SimVP \cite{simvp2022}, PredRNN++ \cite{predrnnpp2018}) and focus on failure modes: fast motion, space-varying dynamics, and error accumulation in long horizons.

\paragraph{Contributions.}
(1) A minimal, clear zero-shot protocol on Moving MNIST; (2) a principled data audit and patch-detaching pipeline; (3) a motion controller that generates speed- and direction-field variants while preserving pixel statistics; (4) sensitivity and breakdown analysis and long-horizon rollouts.

\todo{Add a 4-5 sentence roadmap of sections.}

\section{Related Work}
\textbf{Benchmarks.} OpenSTL standardizes STL evaluation and implementations across recurrent and recurrent-free families \cite{openstl2023}.\\
\textbf{Models.} SimVP shows strong performance with a CNN-only architecture \cite{simvp2022}; PredRNN/PredRNN++ addresses the deep-in-time dilemma for long sequences \cite{predrnnpp2018}.\\
\todo{Add 1-2 more representative works if used as baselines.}

\section{Dataset and Data Audit}
\subsection{Moving MNIST essentials}
Canonical Moving MNIST contains two MNIST digits moving linearly with elastic reflection in a $64\times64$ canvas; common setting is $10 \rightarrow 10$ (past $\to$ future) \cite{srivastava2015}.\\
\textbf{Zero-shot} here means: no fine-tuning or re-training on our test variants; only deterministic, non-learned preprocessing (e.g., normalization) is allowed.

\subsection{Pixel-value audit (what and why)}
\textbf{Goal.} Verify whether frames are strictly binary (0/255) or contain gray edges (anti-aliased boundaries). Gray edges alter reconstruction difficulty and patch extraction.\\
\textbf{Procedure.}
\begin{enumerate}
  \item Sample $N$ sequences and $K$ frames per sequence.
  \item For each frame, compute the set of unique intensities and histograms.
  \item Report presence of gray levels and their spatial localization (edge vs. background).
\end{enumerate}
\textbf{Outputs.} A table of unique-value counts per frame; example histograms; conclusion on binariness.\\
\todo{Insert your measured unique-value stats and representative histograms.}

\section{Digit Patch Detaching}
\textbf{Objective.} Isolate foreground digit patches and their binary masks, while keeping background pure black for deterministic re-composition.

\subsection{Method}
Let $I\in\{0,\dots,255\}^{H\times W}$ be a frame.
\begin{enumerate}
  \item \textbf{Thresholding.} Use a high threshold (e.g., $T\in[180,220]$) to remove soft halos; optionally Otsu if intensity varies across sources. Obtain $\tilde{I}=\mathbf{1}[I\ge T]$.
  \item \textbf{Connected Components.} Keep the two largest components as digit masks $M_1,M_2$. Derive tight bounding boxes $B_1,B_2$.
  \item \textbf{Patch Extraction.} For each $i\in\{1,2\}$, extract $P_i = I\odot M_i$ restricted to $B_i$; store $(P_i,M_i,\text{size}(B_i))$.
  \item \textbf{Background Sanitization.} Replace non-mask pixels in $B_i$ with 0 to ensure a clean black background when re-compositing.
\end{enumerate}
\textbf{Notes.} If edges are gray, prefer morphological opening after thresholding to remove speckles; verify that masks do not leak into the background.

\subsection{Quality checks}
\begin{itemize}
  \item \textbf{Mask IoU stability} across frames for the same digit when re-rendered.
  \item \textbf{Pixel-budget conservation:} $\sum P_i + \text{background} \approx I$ within tolerance.
\end{itemize}
\todo{Insert small table/figures: mask overlays, before/after crops.}

\section{Motion Controller}
We re-render sequences by placing patches on a blank canvas and updating positions via:
\begin{equation}
  \Delta \mathbf{p}_t \;=\; s \cdot v(\mathbf{x}_t)\; \hat{\mathbf{d}}(\mathbf{x}_t), \qquad
  \mathbf{p}_{t+1} = \mathbf{p}_t + \Delta \mathbf{p}_t,
\end{equation}
where $\mathbf{p}_t$ is the patch center at frame $t$, $s$ is a global step multiplier, $v(\cdot)>0$ is a scalar speed field, and $\hat{\mathbf{d}}(\cdot)$ is a unit direction field. On boundary, apply mirror reflection.

\paragraph{Modes.}
\begin{itemize}
  \item \textbf{baseline:} $v(\mathbf{x})\equiv v_0$, $\hat{\mathbf{d}}$ fixed; standard linear motion with reflection.
  \item \textbf{fast:} same as baseline but $s>1$ (e.g., $s\in\{1.5,2,3\}$) to stress fast motion.
  \item \textbf{center-speed:} $v(\mathbf{x}) = v_0 \bigl( 1 + \alpha\,\frac{\|\mathbf{x}-\mathbf{c}\|}{r_{\max}} \bigr)$, $\hat{\mathbf{d}}$ as baseline. Farther from center $\mathbf{c}$, faster it moves.
  \item \textbf{center-direction:} $\hat{\mathbf{d}}(\mathbf{x}) = \frac{\mathbf{c}-\mathbf{x}}{\|\mathbf{c}-\mathbf{x}\|}$ (convergent field), with $v(\mathbf{x})\equiv v_0$.
\end{itemize}
\todo{Add optional variants: vortex fields; soft-wall deceleration; inter-digit soft repulsion.}

\section{Evaluation Protocol}
\subsection{Zero-shot policy}
\begin{itemize}
  \item \textbf{No training / fine-tuning} on our generated variants.
  \item Only deterministic scaling/normalization; channel replication if a model expects multi-channel input.
\end{itemize}

\subsection{Datasets and splits}
$10\to10$ for standard evaluation; optionally long-horizon rollouts by feeding predictions back as inputs to $T=100/200$.

\subsection{Metrics}
\textbf{Frame-level:} MSE, PSNR, SSIM (and optionally LPIPS).\\
\textbf{Trajectory-level (per digit):}
\begin{align}
 \text{Center MAE}: &\;\; \|\hat{\mathbf{c}}_t - \mathbf{c}_t\|_1, \\
 \text{Speed error}: &\;\; \bigl| \|\hat{\mathbf{v}}_t\| - \|\mathbf{v}_t\| \bigr|, \\
 \text{Direction error}: &\;\; \theta_t = \arccos\!\left(\frac{\hat{\mathbf{v}}_t\cdot \mathbf{v}_t}{\|\hat{\mathbf{v}}_t\|\,\|\mathbf{v}_t\|}\right).
\end{align}
\textbf{Plots:} error-vs-time curves; scatter of direction vs. speed errors to test trade-off.

\section{Baselines}
We recommend evaluating at least: SimVP (CNN-only) \cite{simvp2022} and PredRNN++ \cite{predrnnpp2018}, plus 2-3 additional models from OpenSTL's family if available \cite{openstl2023}.\\
\todo{List exact checkpoints and preprocessing for each model; record commit hashes.}

\section{Experiments}
\subsection{E1: Standard Moving MNIST (sanity check)}
\todo{Replicate published numbers; confirm qualitative sharpness vs. motion fidelity.}

\subsection{E2: Fast motion stress}
\todo{Sweep $s\in\{1,1.5,2,3\}$; report frame and trajectory metrics and typical failures (drag, phase lag).}

\subsection{E3: Space-dependent dynamics}
\todo{Center-speed $\alpha \in \{0,0.3,0.6,0.9\}$ and center-direction; show whether models learn field regularities in zero-shot.}

\subsection{E4: Long-horizon rollout}
\todo{Roll to $T=100/200$; compare error accumulation patterns for recurrent vs. non-recurrent models.}

\section{Results and Analysis}
\todo{Insert tables/plots; identify breakdown thresholds; discuss direction-vs-speed error relation; failure-case gallery.}

\section{Ablations and Sensitivity}
\todo{Single-variable sweeps (speed multiplier, field strength), with curves and turning points.}

\section{Limitations and Next Steps}
\todo{Non-black backgrounds; real videos; occlusion handling; digit interactions.}

\section{Reproducibility Checklist}
\begin{itemize}
 \item Seeds, environment (OS, CUDA), package versions.
 \item Data generator configs (\texttt{mode}, $s$, field definitions), and released sequences.
 \item Exact preprocessing and zero-shot arguments per model.
\end{itemize}

\bibliographystyle{plain}
\bibliography{refs}
\end{document}
